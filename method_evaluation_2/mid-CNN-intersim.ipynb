{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "import pickle\n",
        "\n",
        "# Third-party library imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, label_binarize\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# PyTorch imports\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Project-specific imports (MoGoNet)\n",
        "from models.models_mid_CNN import init_model_dict, init_optim\n",
        "from models.train_test_mid_CNN import (\n",
        "    gen_trte_adj_mat, train_epoch, test_epoch\n",
        ")\n",
        "from models.utils import (\n",
        "    save_model_dict, one_hot_tensor, cal_sample_weight,\n",
        "    gen_adj_mat_tensor, gen_test_adj_mat_tensor, cal_adj_mat_parameter\n",
        ")\n",
        "from models.utils2 import evaluate_model, count_trainable_parameters\n",
        "\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 参数设置\n",
        "class_num = 5\n",
        "scenario = 1\n",
        "nn_type = \"mid-CNN\"\n",
        "# signal_prop = \"high\"\n",
        "# signal_level = \"high\"\n",
        "# batch_env = f\"s{scenario}-k3-{signal_prop}-{signal_level}\"\n",
        "# labels_path = f\"F:/r-env/中期/方法/模拟试验-模拟数据/情景{scenario}/k-3/label-k3.csv\"\n",
        "result_path = \"F:/r-env/大课题/模拟试验1_2/result\"\n",
        "prediction_path = \"F:/r-env/大课题/模拟试验1_2/predictions\"\n",
        "# labels = np.loadtxt(f\"F:/r-env/中期/方法/模拟试验-模拟数据/情景{scenario}/k-3/label-k3.csv\", delimiter=',')\n",
        "cuda = torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View and class settings\n",
        "view_list = [1, 2, 3]  # List of views (e.g., modalities)\n",
        "num_view = len(view_list)  # Number of views\n",
        "num_class = 5  # Number of classes\n",
        "# Model dimensionality settings\n",
        "# dim_hvcdn = pow(num_class, num_view)  # Dimension of the H-VCDN\n",
        "# dim_hvcdn = 100 \n",
        "dim_he_list = [16, 32, 100]  # List of dimensions for hidden embeddings\n",
        "# Adjacency matrix settings\n",
        "# adj_parameter = 2  # Parameter controlling adjacency matrix generation\n",
        "# Training and learning rate settings\n",
        "num_epoch_pretrain = 20  # Number of epochs for pretraining\n",
        "num_epoch = 250  # Total number of training epochs\n",
        "lr_e_pretrain = 1e-3  # Learning rate for encoder during pretraining\n",
        "lr_e = 1e-3  # Learning rate for encoder during main training\n",
        "lr_c = 5e-4  # Learning rate for classifier during main training\n",
        "# Testing and evaluation settings\n",
        "test_interval = 2  # Interval for testing the model (in epochs)\n",
        "\n",
        "dropout_rate = 0.1\n",
        "kernal_dim = [8, 4]\n",
        "maxpool_dim = [2, 1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "kfold = StratifiedKFold(n_splits=4, shuffle=True, random_state=2023110400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "开始进行信号比例为 高, 信号水平为 高 的实验\n",
            "开始第 1 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 2 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 3 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 4 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 5 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 6 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 7 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 8 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 9 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 10 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 11 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 12 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 13 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 14 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 15 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 16 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 17 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 18 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 19 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 20 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 21 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 22 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 23 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 24 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 25 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "当前批次实验完成，结果已保存到: F:/r-env/大课题/模拟试验1_2/result\\metrics-mid-CNN-s1-k3-high-high.csv\n",
            "开始进行信号比例为 高, 信号水平为 低 的实验\n",
            "开始第 1 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 2 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 3 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 4 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 5 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 6 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 7 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 8 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 9 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 10 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 11 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 12 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 13 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 14 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 15 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 16 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 17 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 18 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 19 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 20 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 21 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 22 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 23 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 24 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "开始第 25 次模拟实验\n",
            "CV1\n",
            "CV2\n",
            "CV3\n",
            "CV4\n",
            "当前批次实验完成，结果已保存到: F:/r-env/大课题/模拟试验1_2/result\\metrics-mid-CNN-s1-k3-high-low.csv\n",
            "所有实验完成，运行时间已保存到: F:/r-env/大课题/模拟试验1_2/result/mid-CNN_实验运行时间-s2.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 设置信号比例和信号水平的组合\n",
        "signal_props = [\"high\"]\n",
        "# signal_levels = [\"high\", \"mid\", \"low\"]\n",
        "signal_levels = [\"high\", \"low\"]\n",
        "signal_dict = {\n",
        "    \"high\": \"高\",\n",
        "    \"mid\": \"中\",\n",
        "    \"low\": \"低\"\n",
        "}\n",
        "# signal_props = [\"high\"]\n",
        "# signal_levels = [\"high\", \"mid\"]\n",
        "\n",
        "# 保存每次实验的运行时间\n",
        "run_times = []\n",
        "\n",
        "# 创建一个组合的列表，并循环每个组合\n",
        "for signal_prop in signal_props:\n",
        "    for signal_level in signal_levels:\n",
        "        # 获取中文的信号比例和信号水平\n",
        "        ch_sig_prop = signal_dict.get(signal_prop, \"未知\")\n",
        "        ch_sig_level = signal_dict.get(signal_level, \"未知\")\n",
        "\n",
        "        # 设置当前的 batch_env\n",
        "        batch_env = f\"s{scenario}-k3-{signal_prop}-{signal_level}\"\n",
        "\n",
        "        # 打印当前的组合\n",
        "        print(f\"开始进行信号比例为 {ch_sig_prop}, 信号水平为 {ch_sig_level} 的实验\")\n",
        "\n",
        "        metrics = {\"Batch\": [], \"CV\": [], \"Accuracy\": [], \"F1 Macro\": [], \"F1 Micro\": [], \"F1 Weighted\": [],\n",
        "                   \"Precision Macro\": [], \"Precision Micro\": [], \"Precision Weighted\": [],\n",
        "                   \"Recall Macro\": [], \"Recall Micro\": [], \"Recall Weighted\": [],\n",
        "                   \"AUC Macro\": [], \"AUC Micro\": [], \"AUC Weighted\": [],\n",
        "                   \"AUPR Macro\": [], \"AUPR Micro\": [], \"AUPR Weighted\": [], \"Cohen Kappa\": [], \"Training_time\": [], \"GPU_memory_allocated\":[]}\n",
        "        predictions_data = {\"batch_num\": [],\"fold_num\": [],\n",
        "                            \"y_true\": [], \"y_pred\": [],\"proba_1\": [],\"proba_2\": [],\"proba_3\": [],\"proba_4\": [],\"proba_5\": []}\n",
        "        \n",
        "        # 记录实验的开始时间\n",
        "        start_time = time.time()\n",
        "\n",
        "        # 你的实验循环代码\n",
        "        for batch_num in range(1, 26):\n",
        "            print(f\"开始第 {batch_num} 次模拟实验\")\n",
        "\n",
        "            # 数据路径\n",
        "            sim_path = f\"F:/r-env/大课题/模拟数据-intersim/情景{scenario}/k-3/信号比例-{ch_sig_prop}/信号水平-{ch_sig_level}/sim{batch_num}\"\n",
        "            # checkpoint_path = f\"F:/r-env/中期/方法/模拟试验-模型参数/情景{scenario}/k-3/信号比例-{ch_sig_prop}/信号水平-{ch_sig_level}/sim{batch_num}\"\n",
        "\n",
        "            omics1 = np.loadtxt(f\"{sim_path}/s{scenario}-k3-{signal_prop}-{signal_level}-batch{batch_num}-meth.csv\", delimiter=',', skiprows=1)\n",
        "            omics2 = np.loadtxt(f\"{sim_path}/s{scenario}-k3-{signal_prop}-{signal_level}-batch{batch_num}-mrna.csv\", delimiter=',', skiprows=1)\n",
        "            omics3 = np.loadtxt(f\"{sim_path}/s{scenario}-k3-{signal_prop}-{signal_level}-batch{batch_num}-prot.csv\", delimiter=',', skiprows=1)\n",
        "            labels = np.loadtxt(f\"{sim_path}/s{scenario}-k3-{signal_prop}-{signal_level}-batch{batch_num}-label.csv\", delimiter=',', skiprows=1)\n",
        "            \n",
        "            # scaler = MinMaxScaler()\n",
        "            # omics1_scaled = scaler.fit_transform(omics1) # 对 omics1 数据框的每列特征进行放缩\n",
        "            # omics2_scaled = scaler.fit_transform(omics2) # 对 omics2 数据框的每列特征进行放缩\n",
        "            \n",
        "            # omics = np.concatenate((omics1, omics2, omics3), axis=1)\n",
        "\n",
        "            omics_data = [omics1, omics2, omics3]\n",
        "\n",
        "            for fold_num, (train_idx_raw, test_idx) in enumerate(kfold.split(omics1, labels)):\n",
        "                print(f\"CV{fold_num + 1}\")\n",
        "\n",
        "                # 将train_idx_raw按3:1划分为train_idx和val_idx\n",
        "                train_idx, val_idx = train_test_split(\n",
        "                    train_idx_raw, \n",
        "                    test_size=0.25,  # 25%作为验证集，75%作为训练集 (3:1比例)\n",
        "                    random_state=42,\n",
        "                    stratify=labels[train_idx_raw]  # 保持标签分布\n",
        "                )\n",
        "\n",
        "                \n",
        "                data_tr_list = []\n",
        "                data_val_list = []\n",
        "                data_te_list = []\n",
        "                data_trval_list = []\n",
        "                data_trte_list = []\n",
        "\n",
        "                # 通过循环处理每个omics数据集\n",
        "                for omic in omics_data:\n",
        "                    train_X = omic[train_idx]\n",
        "                    val_X = omic[val_idx]\n",
        "                    test_X = omic[test_idx]\n",
        "                    data_tr_list.append(torch.FloatTensor(train_X).cuda() )\n",
        "                    data_val_list.append(torch.FloatTensor(val_X).cuda() )\n",
        "                    data_te_list.append(torch.FloatTensor(test_X).cuda() )\n",
        "                    data_trval_list.append(torch.FloatTensor(np.concatenate((train_X, val_X), axis=0)).cuda() )\n",
        "                    data_trte_list.append(torch.FloatTensor(np.concatenate((train_X, test_X), axis=0)).cuda() )\n",
        "\n",
        "                train_y, val_y, test_y = labels[train_idx], labels[val_idx], labels[test_idx]\n",
        "\n",
        "                # model_filepath = os.path.join(checkpoint_path, f\"early-GCN-model{fold_num + 1}\")\n",
        "                # os.makedirs(model_filepath, exist_ok=True)\n",
        "                # checkpoint = ModelCheckpoint(model_filepath, save_weights_only=True, monitor='val_acc', save_best_only=True, mode='max')\n",
        "\n",
        "                # View and class settings\n",
        "\n",
        "                # torch.cuda.empty_cache()\n",
        "\n",
        "                # 准备数据\n",
        "                # data_tr_list = [torch.FloatTensor(train_X)]\n",
        "                # data_trval_list = [torch.FloatTensor(np.concatenate((train_X, val_X), axis=0))]\n",
        "                # data_trte_list = [torch.FloatTensor(np.concatenate((train_X, test_X), axis=0))]\n",
        "\n",
        "                if cuda:\n",
        "                    data_tr_list[0] = data_tr_list[0].cuda()\n",
        "                    data_trval_list[0] = data_trval_list[0].cuda()\n",
        "                    data_trte_list[0] = data_trte_list[0].cuda()\n",
        "\n",
        "                num_tr = data_tr_list[0].shape[0]\n",
        "                num_trval = data_trval_list[0].shape[0]\n",
        "                num_trte = data_trte_list[0].shape[0]\n",
        "\n",
        "                labels_trval = np.concatenate((train_y, val_y))\n",
        "                labels_trte = np.concatenate((train_y, test_y))\n",
        "\n",
        "                trval_idx = {\n",
        "                    \"tr\": list(range(num_tr)),\n",
        "                    \"te\": list(range(num_tr, num_trval))\n",
        "                }\n",
        "                \n",
        "                trte_idx = {\n",
        "                    \"tr\": list(range(num_tr)),\n",
        "                    \"te\": list(range(num_tr, num_trte))\n",
        "                }\n",
        "                \n",
        "                labels_tr_tensor = torch.LongTensor(labels_trval[trval_idx[\"tr\"]])\n",
        "                onehot_labels_tr_tensor = one_hot_tensor(labels_tr_tensor, num_class)\n",
        "                sample_weight_tr = torch.FloatTensor(cal_sample_weight(labels_trval[trval_idx[\"tr\"]], num_class))\n",
        "                \n",
        "                if cuda:\n",
        "                    labels_tr_tensor = labels_tr_tensor.cuda()\n",
        "                    onehot_labels_tr_tensor = onehot_labels_tr_tensor.cuda()\n",
        "                    sample_weight_tr = sample_weight_tr.cuda()\n",
        "\n",
        "                dim_list = [x.shape[1] for x in data_tr_list]\n",
        "\n",
        "                # 初始化模型\n",
        "                model_dict = init_model_dict(num_view, num_class, dim_list, dim_he_list, kernal_dim, maxpool_dim, dropout_rate, dropout_c = 0)\n",
        "                optim_dict = init_optim(num_view, model_dict, lr_e_pretrain, lr_c)\n",
        "                \n",
        "                for model in model_dict.values():\n",
        "                    if cuda:\n",
        "                        model.cuda()\n",
        "\n",
        "                \n",
        "                # 记录单个fold的开始时间\n",
        "                fold_start_time = time.time()\n",
        "\n",
        "\n",
        "                # 预训练\n",
        "                for epoch in range(num_epoch_pretrain):\n",
        "                    train_epoch(data_tr_list,  labels_tr_tensor, \n",
        "                                onehot_labels_tr_tensor, sample_weight_tr, model_dict, optim_dict, train_fusion=True)\n",
        "                \n",
        "                # 主训练\n",
        "                optim_dict = init_optim(num_view, model_dict, lr_e, lr_c)\n",
        "\n",
        "                # 早停机制\n",
        "                best_accuracy = 0.0\n",
        "                patience = 25\n",
        "                no_improvement_count = 0\n",
        "                best_model = None\n",
        "\n",
        "\n",
        "                for epoch in range(num_epoch):\n",
        "                    train_epoch(data_tr_list, labels_tr_tensor, \n",
        "                               onehot_labels_tr_tensor, sample_weight_tr, model_dict, optim_dict, train_fusion=True)\n",
        "                    \n",
        "                    # 每10个epoch验证一次\n",
        "                    if epoch % 2 == 0:\n",
        "                        val_prob = test_epoch(data_trval_list, trval_idx[\"te\"], model_dict) ####\n",
        "                        predictions = np.argmax(val_prob, axis=1)\n",
        "                        accuracy = accuracy_score(val_y, predictions)\n",
        "                        \n",
        "                        if accuracy > best_accuracy:\n",
        "                            best_accuracy = accuracy\n",
        "                            no_improvement_count = 0\n",
        "                            best_model = copy.deepcopy(model_dict)\n",
        "                        else:\n",
        "                            no_improvement_count += 2\n",
        "                            \n",
        "                        if no_improvement_count >= patience:\n",
        "                            break\n",
        "                        # 记录单个fold的结束时间\n",
        "                # log_gpu_memory()\n",
        "                fold_end_time = time.time()\n",
        "                fold_elapsed_time = fold_end_time - fold_start_time\n",
        "\n",
        "                memory_allocated = torch.cuda.memory_allocated() / 1024**2\n",
        "\n",
        "                # 最终测试\n",
        "                predictions = test_epoch(data_trte_list, trte_idx[\"te\"], best_model)\n",
        "                y_pred = np.argmax(predictions, axis=1)\n",
        "                # y_true = labels_trte[trte_idx[\"te\"]]    \n",
        "                y_true = test_y\n",
        "\n",
        "                prediction_to_add = {\n",
        "                    \"batch_num\": batch_num,  \n",
        "                    \"fold_num\": fold_num + 1, \n",
        "                    \"y_true\": y_true.tolist(),\n",
        "                    \"y_pred\": y_pred.tolist(),\n",
        "                    \"proba_1\": predictions[:, 0].tolist(),\n",
        "                    \"proba_2\": predictions[:, 1].tolist(),\n",
        "                    \"proba_3\": predictions[:, 2].tolist(),\n",
        "                    \"proba_4\": predictions[:, 3].tolist(),\n",
        "                    \"proba_5\": predictions[:, 4].tolist()\n",
        "                }\n",
        "\n",
        "                for key, values in prediction_to_add.items():\n",
        "                    if key in [\"y_true\", \"y_pred\", \"proba_1\", \"proba_2\", \"proba_3\", \"proba_4\", \"proba_5\"]:\n",
        "                        predictions_data[key].extend(values)\n",
        "                    else:\n",
        "                        predictions_data[key].extend([values] * len(y_true))\n",
        "                        # predictions_data[key].append(values)  \n",
        "        \n",
        "\n",
        "                scores = evaluate_model(y_true, y_pred, predictions, class_num)\n",
        "\n",
        "                for key in metrics:\n",
        "                    if key == \"Batch\":\n",
        "                        metrics[key].append(batch_num)\n",
        "                    elif key == \"CV\":\n",
        "                        metrics[key].append(fold_num + 1)\n",
        "                    elif key == \"Training_time\":\n",
        "                        metrics[key].append(fold_elapsed_time)\n",
        "                    elif key == \"GPU_memory_allocated\":\n",
        "                        metrics[key].append(memory_allocated)  # 记录 GPU 内存占用\n",
        "                    else:\n",
        "                        metrics[key].append(scores.get(key, None))  # 没有的指标填None\n",
        "\n",
        "        end_time = time.time() \n",
        "\n",
        "        trainable_params = count_trainable_parameters(model_dict)\n",
        "        # print(f\"模型可训练参数数量: {trainable_params:,}\")\n",
        "        \n",
        "        metrics_df = pd.DataFrame(metrics)\n",
        "        float_cols = metrics_df.select_dtypes(include=['float64']).columns\n",
        "        metrics_df[float_cols] = metrics_df[float_cols].round(6)\n",
        "        result_filepath = os.path.join(result_path, f\"metrics-{nn_type}-{batch_env}.csv\")\n",
        "        metrics_df.to_csv(result_filepath, index=False)\n",
        "\n",
        "        predictions_data = pd.DataFrame(predictions_data)\n",
        "        if not predictions_data.empty:\n",
        "            # 筛选需要保留4位小数的列\n",
        "            float_cols = ['proba_1', 'proba_2', 'proba_3', \"proba_4\", \"proba_5\"]  # 根据你的实际列名调整\n",
        "            # 应用四舍五入\n",
        "            predictions_data[float_cols] = predictions_data[float_cols].round(4)\n",
        "        predictions_filepath = os.path.join(prediction_path, f\"prediction-{nn_type}-{batch_env}.csv\")\n",
        "        predictions_data.to_csv(predictions_filepath, index=False)\n",
        "        print(f\"当前批次实验完成，结果已保存到: {result_filepath}\")\n",
        "\n",
        "\n",
        "        elapsed_time = end_time - start_time  # 计算每次实验的运行时间\n",
        "        run_times.append({\n",
        "            \"signal_prop\": signal_prop,\n",
        "            \"signal_level\": signal_level,\n",
        "            \"training_num\": batch_num * 4,\n",
        "            \"elapsed_time\": elapsed_time,   \n",
        "            \"trainable_params\": trainable_params\n",
        "        })\n",
        "\n",
        "        \n",
        "# 将所有运行时间保存到 CSV 文件\n",
        "run_times_df = pd.DataFrame(run_times)\n",
        "result_filepath = f\"{result_path}/{nn_type}_实验运行时间-s2.csv\"\n",
        "run_times_df.to_csv(result_filepath, index=False)\n",
        "\n",
        "print(f\"所有实验完成，运行时间已保存到: {result_filepath}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}